{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Séance 2 - Calibration\n",
        "\n",
        "On se propose dans ce notebook d'explorer une manière de recalibrer un modèle machine learning.\n",
        "Pour le faire, nous allons travailler avec un dataset déséquilibré qui a pour but de prédire si une étoile est un pulsar ou non. On ne s'intéresse pas au travail de feature engineering ici."
      ],
      "metadata": {
        "id": "CbgVPoXOPJeA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ki1tOkKKIpo9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "360d7f4b-bd05-412d-910b-ec64263ab3a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Mean_ip     Std_ip  Excess_kurtosis_ip  Skewness_ip   Mean_DM  \\\n",
              "0  140.562500  55.683782           -0.234571    -0.699648  3.199833   \n",
              "1  102.507812  58.882430            0.465318    -0.515088  1.677258   \n",
              "2  103.015625  39.341649            0.323328     1.051164  3.121237   \n",
              "3  136.750000  57.178449           -0.068415    -0.636238  3.642977   \n",
              "4   88.726562  40.672225            0.600866     1.123492  1.178930   \n",
              "\n",
              "      Std_DM  Excess_kurtosis_DM  Skewness_DM  target  \n",
              "0  19.110426            7.975532    74.242225       0  \n",
              "1  14.860146           10.576487   127.393580       0  \n",
              "2  21.744669            7.735822    63.171909       0  \n",
              "3  20.959280            6.896499    53.593661       0  \n",
              "4  11.468720           14.269573   252.567306       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1174f8e9-859d-4bc8-916d-a295db1ee115\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean_ip</th>\n",
              "      <th>Std_ip</th>\n",
              "      <th>Excess_kurtosis_ip</th>\n",
              "      <th>Skewness_ip</th>\n",
              "      <th>Mean_DM</th>\n",
              "      <th>Std_DM</th>\n",
              "      <th>Excess_kurtosis_DM</th>\n",
              "      <th>Skewness_DM</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>140.562500</td>\n",
              "      <td>55.683782</td>\n",
              "      <td>-0.234571</td>\n",
              "      <td>-0.699648</td>\n",
              "      <td>3.199833</td>\n",
              "      <td>19.110426</td>\n",
              "      <td>7.975532</td>\n",
              "      <td>74.242225</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>102.507812</td>\n",
              "      <td>58.882430</td>\n",
              "      <td>0.465318</td>\n",
              "      <td>-0.515088</td>\n",
              "      <td>1.677258</td>\n",
              "      <td>14.860146</td>\n",
              "      <td>10.576487</td>\n",
              "      <td>127.393580</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>103.015625</td>\n",
              "      <td>39.341649</td>\n",
              "      <td>0.323328</td>\n",
              "      <td>1.051164</td>\n",
              "      <td>3.121237</td>\n",
              "      <td>21.744669</td>\n",
              "      <td>7.735822</td>\n",
              "      <td>63.171909</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>136.750000</td>\n",
              "      <td>57.178449</td>\n",
              "      <td>-0.068415</td>\n",
              "      <td>-0.636238</td>\n",
              "      <td>3.642977</td>\n",
              "      <td>20.959280</td>\n",
              "      <td>6.896499</td>\n",
              "      <td>53.593661</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>88.726562</td>\n",
              "      <td>40.672225</td>\n",
              "      <td>0.600866</td>\n",
              "      <td>1.123492</td>\n",
              "      <td>1.178930</td>\n",
              "      <td>11.468720</td>\n",
              "      <td>14.269573</td>\n",
              "      <td>252.567306</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1174f8e9-859d-4bc8-916d-a295db1ee115')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1174f8e9-859d-4bc8-916d-a295db1ee115 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1174f8e9-859d-4bc8-916d-a295db1ee115');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bbce14e0-4e07-4760-b980-a16b5dbc5267\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bbce14e0-4e07-4760-b980-a16b5dbc5267')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bbce14e0-4e07-4760-b980-a16b5dbc5267 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 17898,\n  \"fields\": [\n    {\n      \"column\": \"Mean_ip\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.652935359860106,\n        \"min\": 5.8125,\n        \"max\": 192.6171875,\n        \"num_unique_values\": 8626,\n        \"samples\": [\n          83.265625,\n          51.9453125,\n          120.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Std_ip\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.843189410087772,\n        \"min\": 24.77204176,\n        \"max\": 98.77891067,\n        \"num_unique_values\": 17862,\n        \"samples\": [\n          48.17823507,\n          50.13572825,\n          53.11199232\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Excess_kurtosis_ip\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0640397163731556,\n        \"min\": -1.876011181,\n        \"max\": 8.069522046,\n        \"num_unique_values\": 17897,\n        \"samples\": [\n          0.175111538,\n          2.02549836,\n          0.504295246\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Skewness_ip\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.167913247731735,\n        \"min\": -1.791885981,\n        \"max\": 68.10162173,\n        \"num_unique_values\": 17898,\n        \"samples\": [\n          -0.129815137,\n          8.652912976,\n          0.821088334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean_DM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29.472897150065176,\n        \"min\": 0.213210702,\n        \"max\": 223.3921405,\n        \"num_unique_values\": 9000,\n        \"samples\": [\n          3.387123746,\n          4.147157191,\n          3.241638796\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Std_DM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.470572330539163,\n        \"min\": 7.370432165,\n        \"max\": 110.6422106,\n        \"num_unique_values\": 17894,\n        \"samples\": [\n          16.7127396,\n          11.35208188,\n          11.14631778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Excess_kurtosis_DM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.506091858992771,\n        \"min\": -3.139269611,\n        \"max\": 34.53984419,\n        \"num_unique_values\": 17895,\n        \"samples\": [\n          10.49423164,\n          8.479589229,\n          8.236539915\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Skewness_DM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 106.51453953467565,\n        \"min\": -1.976975603,\n        \"max\": 1191.000837,\n        \"num_unique_values\": 17895,\n        \"samples\": [\n          153.2811187,\n          92.51934407,\n          84.30255822\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set(style='whitegrid')\n",
        "\n",
        "df = pd.read_csv(\"pulsar_stars.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consigne** : Est-on dans un problème de classification déséquilibré ?"
      ],
      "metadata": {
        "id": "iEasOKJBLzVm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HYLJhS8IL5Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons découper le dataset en trois parties:\n",
        "* **Train** : entraîner le prédicteur\n",
        "* **Validation** : recalibrer les prédictions\n",
        "* **Test** : mesurer les performances du modèle\n",
        "\n",
        "**Consignes** : Générer les trois bases puis les standardiser les trois bases. Enfin, afficher les tailles et la proportion de déséquilibre de chaque bases."
      ],
      "metadata": {
        "id": "vSFWCRU3PcEP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OwtOl2vOzhct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous remarquons que l'on travaille avec un dataset qui est déséquilibré de l'ordre de 9% de présence de la classe d'intérêt. Nous verrons comment cela peut impacter les prédictions.\n",
        "\n",
        "## Entraînement du prédicteur\n",
        "\n",
        "On décide de travailler avec une régression logistique et de mesurer les performances avec les métriques usuelles.\n",
        "\n",
        "**Consigne** : Entraîner une régression logistique et prédire sur jeu de test."
      ],
      "metadata": {
        "id": "aIL7PtH2P39d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xmk3lFAb1QAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On souhaite avoir une fonction de mesure de la performance selon plusieurs métriques.\n",
        "La fonction s'appellera *print_performances* et prendra en paramètres:\n",
        "* *y_true* : vecteur qui contient les vraies valeurs\n",
        "* *y_pred* : vecteur qui contient les valeurs prédites\n",
        "* *metrics* : une liste de métrique stockées sous forme de fontion au format scikit-learn. Par défaut, placer l'accuracy.\n",
        "Cette fonction affichera le nom de la métrique et la valeur de la performance.\n",
        "\n",
        "**Consigne** : rédiger cette fonction. On pourra utiliser le nom de la classe pour le nom de la métrique. Par exemple pour l'accuracy:"
      ],
      "metadata": {
        "id": "zo2y42CrMK9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score.__name__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5-gF4BVMy-2",
        "outputId": "e0e3adcb-3b9c-40a2-948d-985c07db9571"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ...\n",
        "\n",
        "def print_performances(y_true, y_pred, metrics=[accuracy_score]):\n",
        "  ..."
      ],
      "metadata": {
        "id": "0xnuH6vX1yVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recalibration\n",
        "\n",
        "Il existe de nombreuse manière de recalibrer les prédictions. On décide de le faire par la température, qui est probablement la manière la plus simple pour travailler.\n",
        "\n",
        "On appelle **température** le scalaire $\\tau > 0$ qui modifie les prédictions (avant normalisation) $(y_i)_{i\\leqslant n}$ comme suit:\n",
        "\n",
        "$$\\forall i \\leqslant n, \\quad \\tilde{y_i} = \\frac{\\displaystyle \\exp\\left(\\frac{y_i}{\\tau}\\right)}{\\displaystyle \\sum_{j=1}^n \\exp\\left(\\frac{y_j}{\\tau}\\right)}$$\n",
        "\n",
        "Ainsi, si $\\tau=1$ cela ne change pas les prédictions. Voyons quel impact ce paramètre a.\n",
        "Nous allons avoir besoin à plusieurs reprise de deux fonctions:\n",
        "* La fonction sigmoid : $\\displaystyle \\sigma(x) = \\frac{1}{1+\\exp(-x)}$\n",
        "* Son inverse : $\\displaystyle \\sigma^{-1}(x) = \\log\\left(\\frac{x}{1—x}\\right)$\n",
        "Pour ne pas avoir de problème numérique avec $\\sigma^{-1}$, on va ajouter deux epsilons : $\\displaystyle \\tilde{\\sigma^{-1}} = \\ln\\left(\\frac{x}{1—x+\\varepsilon}+\\varepsilon\\right)$. De cette manière, on évite de diviser par zéro, et on évite d'avoir une valeur négative dans le logarithme.\n",
        "\n",
        "\n",
        "**Consigne** : Ecrire la fonction *temperature* qui prend en paramètre:\n",
        "* *probabilities* : un vecteur de prédiction, pas des logits\n",
        "* *tau* : valeur numérique, par défaut 1"
      ],
      "metadata": {
        "id": "kDZvWLFSQP0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid = lambda x: 1 / (1+np.exp(-x))\n",
        "def logit(x, epsilon=1e-8):\n",
        "  return np.log(x / (1-x + epsilon) + epsilon)\n",
        "\n",
        "def temperature(probabilities, tau=1):\n",
        "  ..."
      ],
      "metadata": {
        "id": "fEcamyr63stC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avec la méthode *predict_proba* on obtient une matrice de prédiction. Dans notre cas, on a pour chaque observation (*i.e* chaque lignes) la prédiction d'appartenance à chaque classe (ici deux possibilités).\n",
        "\n",
        "**Consigne** : tracer la distribution de la probabilités d'être un pulsar selon plusieurs valeur de température."
      ],
      "metadata": {
        "id": "xuERhNicn8LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9edxnh544Xbj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On se propose de trouver la meilleure valeur de $\\tau$ pour calibrer au mieux les prédictions."
      ],
      "metadata": {
        "id": "liBBFEspRzEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trouver la meilleure valeur de $\\tau$\n",
        "\n",
        "Pour le faire, nous allons utiliser les capacités d'optimisations de PyTorch. Puisque la *loss* qu'optimise la régression logistique est la *Cross-Entropy*, on va chercher à optimiser cette même loss sur les prédictions du jeu de validation.\n",
        "\n",
        "Commençons par préparer les objets dont nous aurons besoins:\n",
        "* Initialiser l'objet qui représentera la cross-entropie\n",
        "* Calculer les probabilités prédites pour chaque observations du dataset de validation et les transformer en logits\n",
        "\n",
        "**Consigne** : Compléter le code ci-dessous."
      ],
      "metadata": {
        "id": "Dvwrk2NeN-zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "loss = CrossEntropyLoss()\n",
        "probabilities_validation = model.predict_proba(...)\n",
        "y_valid_tensor = torch.Tensor(np.array(...)).type(torch.LongTensor)\n",
        "logits = torch.Tensor(logit(...))"
      ],
      "metadata": {
        "id": "Ryd4BqMgPjbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous aurons également besoin d'initialiser le paramètre $\\tau$ que l'on va apprendre et l'objet qui représentera l'optimizer. On décide de travailler avec [LBFGS](https://fr.wikipedia.org/wiki/Méthode_de_Broyden-Fletcher-Goldfarb-Shanno#:~:text=En%20mathématiques%2C%20la%20méthode%20de,algorithme%20à%20directions%20de%20descente.)."
      ],
      "metadata": {
        "id": "fDR4nEnESqCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tau_value = torch.nn.Parameter(torch.ones(1))\n",
        "optimizer = torch.optim.LBFGS([tau_value], lr=0.01, max_iter=1000)"
      ],
      "metadata": {
        "id": "tQdOPYk4UCNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculons la valeur de la perte avant le post-processing :"
      ],
      "metadata": {
        "id": "OygoWSGgTJBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaled = logits / tau_value.unsqueeze(1).expand(logits.size(0), logits.size(1))\n",
        "loss_value = loss(scaled, y_valid_tensor)\n",
        "print(f\"Tau={tau_value.item()}, Loss={loss_value.item():0.4f}\")"
      ],
      "metadata": {
        "id": "SBaWDQRnpWms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mettons en place la boucle d'optimisation :"
      ],
      "metadata": {
        "id": "aTeKhNiFTNTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval():\n",
        "  optimizer.zero_grad()\n",
        "  scaled = logits / tau_value.unsqueeze(1).expand(logits.size(0), logits.size(1))\n",
        "  loss_value = loss(scaled, y_valid_tensor)\n",
        "  loss_value.backward()\n",
        "  return loss_value\n",
        "\n",
        "optimizer.step(eval)\n",
        "\n",
        "scaled = logits / tau_value.unsqueeze(1).expand(logits.size(0), logits.size(1))\n",
        "loss_value = loss(scaled, y_valid_tensor)\n",
        "print(f\"Tau={tau_value.item()}, Loss={loss_value.item():0.4f}\")"
      ],
      "metadata": {
        "id": "DsuyvN4upZRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La fonction de perte est bien plus faible après ce processing en passant de 0.10 à 0.07. Avant de continuer, essayons de rendre plus simple cette optimisation en construisant une unique fonction.\n",
        "\n",
        "\n",
        "**Consigne** : Rédiger une fonction qui prend en paramètres:\n",
        "* *model*: modèle type scikit-learn, entraîné\n",
        "* *X*: base de donnée à partir de laquelle les prédictions seront faites\n",
        "* *y*: vecteur des prédictions attendues\n",
        "Elle devra trouver la valeur optimale de température comme décrit ci-dessus."
      ],
      "metadata": {
        "id": "V55VLzBCTQqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def temperature_scaling(model, X, y):\n",
        "  ..."
      ],
      "metadata": {
        "id": "wxyk_oy2ULeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant que l'on sait trouver la valeur optimale de température pour optimiser la performance de la loss sur le jeu de validation, on aimerait savoir si ça se traduit de la même manière pour les autres datasets.\n",
        "\n",
        "**Consigne** : pour chaque dataset, calculer la valeur de la loss avant et après le scaling par température."
      ],
      "metadata": {
        "id": "Uzprcb19ULxG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLCHGGUpravO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On veut visualiser le changement du scaling de température sur les différentes métrique.\n",
        "Pour cela, on construit une fonction qui va nous permettre de voir plus plusieurs seuils la valeur de la précision, du recall et du f1-score.\n",
        "\n",
        "**Consigne** : Compléter la fonction."
      ],
      "metadata": {
        "id": "FEZupbWiTY6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(y_score, show=True):\n",
        "  precision = []\n",
        "  recall = []\n",
        "  f1 = []\n",
        "  thresholds = np.linspace(start=0.001, stop=0.99, num=50)\n",
        "\n",
        "  for threshold in thresholds:\n",
        "    y_pred = y_score[:, 1] > threshold\n",
        "    precision.append(...)\n",
        "    recall.append(...)\n",
        "    f1.append(...)\n",
        "\n",
        "  plt.axhline(y=np.max(f1), ls='--', alpha=0.8, color=sns.color_palette()[2])\n",
        "\n",
        "  plt.plot(thresholds, precision, label=\"Precision\")\n",
        "  plt.plot(thresholds, recall, label=\"Recall\")\n",
        "  plt.plot(thresholds, f1, label=\"F1-Score\", lw=2)\n",
        "\n",
        "  plt.scatter(thresholds[np.argmax(f1)], precision[np.argmax(f1)])\n",
        "  plt.scatter(thresholds[np.argmax(f1)], recall[np.argmax(f1)])\n",
        "  plt.scatter(thresholds[np.argmax(f1)], max(f1))\n",
        "  plt.ylim(0, 1)\n",
        "  plt.legend()\n",
        "  if show: plt.show()"
      ],
      "metadata": {
        "id": "QeOucgC6pS9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consigne** : Exploiter la fonction complétée sur les prédictions sur le jeu de test. On veut voir la différence avant et après le scaling."
      ],
      "metadata": {
        "id": "yqIwi8FKsMYp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vHNolg2KsYej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Et la calibration ?\n",
        "\n",
        "Jusqu'ici nous avons optimisé la loss avec un post-processing. Nous avons vu en cours que la performance en terme de calibration est également lié à un gain de performance suite à un post-processing.\n",
        "Nous nous attendons donc à avoir une meilleure calibration après le scaling par la température.\n",
        "\n",
        "Pour l'observer visuellement, nous pouvons utiliser la fonction *calibration_curve* de [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.calibration.calibration_curve.html).\n",
        "\n",
        "**Consigne** : Visualiser la courbe de calibration avant et après le scaling, en traçant également le prédicteur parfaitement calibré."
      ],
      "metadata": {
        "id": "9-56rFxmsm_I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P3SLiqjltLcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pour continuer\n",
        "\n",
        "Nous avons construit tout un tas de fonction pour faciliter le travail. Utilisez les fonctions pour reproduire l'étude avec d'autres algorithmes !"
      ],
      "metadata": {
        "id": "pYPZZUo3T5_T"
      }
    }
  ]
}