{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Séance 1 - EarlyDropout\n",
        "\n",
        "On se propose dans ce notebook de reproduire une partie de l'article [Dropout reduces underfitting](https://arxiv.org/abs/2303.01500). Pour le vérifier, nous allons utiliser le dataset Fashion MNIST. Commençons par importer les packages dont nous aurons besoin, importer et standardiser les données."
      ],
      "metadata": {
        "id": "8p7cliyIIpLX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8RlRJKbkm9B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set(style='whitegrid')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train, y_train), (X_valid, y_valid) = (fashion_mnist.load_data())\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train.astype(np.float32).reshape(-1, 28 * 28)).reshape(-1, 28, 28, 1)\n",
        "X_valid = scaler.transform(X_valid.astype(np.float32).reshape(-1, 28 * 28)).reshape(-1, 28, 28, 1)\n",
        "\n",
        "\n",
        "label_map = {0: \"t-shirt/top\", 1: \"trouser\", 2: \"pullover\",\n",
        "             3: \"dress\", 4: \"coat\", 5: \"sandal\",\n",
        "             6: \"shirt\", 7: \"sneaker\", 8: \"bag\", 9: \"ankle boot\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisons quelques exemples :"
      ],
      "metadata": {
        "id": "mfnr_V3vQ2xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5\n",
        "\n",
        "plt.figure(figsize=(13, 6))\n",
        "for plot_index in range(1, n+1):\n",
        "  plt.subplot(1, n, plot_index)\n",
        "  index = np.random.randint(low=0, high=len(X_train))\n",
        "  plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
        "  plt.title(\"Image of a %s\" % label_map[y_train[index]])\n",
        "  plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QsN0aNMWQrAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EarlyDropout\n",
        "\n",
        "L'early dropout tel que définit dans l'article correspond à avoir la probabilité de dropout strictement supérieure à zéro jusqu'à une certaine époque. Après la valeur vaut 0.\n",
        "\n",
        "Pour pouvoir reproduire ce fonctionnement, nous allons devoir définir notre propre [callback](https://keras.io/guides/writing_your_own_callbacks/) pour modifier le réseau de neurones pendant l'entraînement.\n",
        "Nous aurons besoin de :\n",
        "* La valeur initiale du taux de dropout\n",
        "* L'époque à laquelle on devra *arrêter* le dropout\n",
        "\n",
        "**Consigne** : Ecrire la classe *EarlyDropout* selon le template suivant. Pour information, le paramètre *epoch* vaut 0 pour l'époque numéroté 1 dans l'affichage habituel.\n"
      ],
      "metadata": {
        "id": "1nEIyvKTJEJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyDropout(keras.callbacks.Callback):\n",
        "  def __init__(self, ...):\n",
        "    ...\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    ..."
      ],
      "metadata": {
        "id": "ibOCixqvlO_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Réseau de neurones\n",
        "Définissons à présent le réseau convolutionnel que l'on va exploiter. Pour pouvoir simplement mesurer l'apport (ou non) de l'early dropout, nous allons définir une fonction qui définira, entraînera et renverra les performances de l'entraînement du réseau de neurones.\n",
        "Nous aurons besoin de définir les paramètres:\n",
        "* **Early dropout** : la valeur du dropout et l'époque de fin d'utilisation\n",
        "* **Entraînement** : le learning rate et le nombre d'époque\n",
        "\n",
        "**Consigne** : Renseigner la fonction *generate_train_model* suivante. On ajoutera un paramètre *verbose* à la fonction pour contrôler le même paramètre dans l'appel *.fit* pour ne pas avoir la totalité des affichages.\n",
        "On définira le variable *dropout_rate_variable* avec une valeur réelle à spécifier à l'aide de la fonction *keras.backend.variable*. De cette manière on pourra la modifier avec la classe EarlyDropout précédente.\n",
        "Vous êtes libre de modifier à volonté la définition du réseau de neurones."
      ],
      "metadata": {
        "id": "4loOiPfgJ_ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_train_model(...):\n",
        "  dropout_rate_variable = keras.backend.variable(...)\n",
        "\n",
        "  model = keras.models.Sequential([\n",
        "    ...\n",
        "  ])\n",
        "\n",
        "  callback = EarlyDropout(...)\n",
        "\n",
        "  model.compile(...)\n",
        "  history = model.fit(...)\n",
        "  return pd.DataFrame(history.history)"
      ],
      "metadata": {
        "id": "mWL7SIIOk9iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparer plusieurs choix\n",
        "\n",
        "Pour simplifier l'écriture de multiple test, et simplifier le stockage des historiques d'apprentissage, on se propose d'utiliser une fonction pour le faire.\n",
        "Elle nécessite une liste d'expériences à réaliser. Chaque expérience est un dictionnaire que l'on paramètre avec:\n",
        "* **type** : le nom de l'expérience\n",
        "* **function** : la fonction qui génére l'historique d'apprentissage\n",
        "* **parameters** : les paramètres à renseigner pour appeler la fonction *function*\n",
        "\n",
        "Cette fonction réalisera l'ensemble des expériences un certain nombre de fois pour pouvoir potentiellement estimer un interval de confiance."
      ],
      "metadata": {
        "id": "Fy64YYoGKw3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_architectures(comparisons, comparisons_number=2):\n",
        "  results = []\n",
        "\n",
        "\n",
        "  for index in range(comparisons_number):\n",
        "    print(\"Comparison %d :\" % (index+1), end=\" \")\n",
        "\n",
        "    for element in comparisons:\n",
        "      print(\"%s...\" % element[\"type\"], end= \" \")\n",
        "      function, parameters = element[\"function\"], element[\"parameters\"]\n",
        "      history = function(**parameters)\n",
        "      result = {\"type\": element[\"type\"], \"history\": history}\n",
        "      results.append(result)\n",
        "\n",
        "    print()\n",
        "\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "XwDtqBDflOVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il ne nous reste plus qu'à générer le dictionnaire d'expériences ! Nous entraînerons sur 20 époques uniquement les réseaux de neurones. Nous considérons ici uniquement trois expériences:\n",
        "* Un réseau avec un EarlyDropout au bout de 10 époques\n",
        "* Un réseau avec un EarlyDropout au bout de 20 époques, autrement dit avec dropout tout au long de l'entraînement\n",
        "* Un réseau avec un EarlyDropout au bout de 0 époques, autrement dit sans dropout tout au long de l'entraînement\n",
        "\n",
        "**Consigne** : Remplir la cellule ci-dessous pour générer les expériences que l'on souhaite réaliser en accord avec les informations précédentes."
      ],
      "metadata": {
        "id": "osre48lKLfGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropout_rate = 0.5\n",
        "learning_rate = 5e-4\n",
        "n_epochs = ...\n",
        "epochs = [...]\n",
        "\n",
        "\n",
        "comparisons = []\n",
        "\n",
        "for epoch in epochs:\n",
        "  parameters = {...}\n",
        "\n",
        "  comparison = {\"type\": \"EarlyDropout %d epochs\" % epoch,\n",
        "                \"function\": generate_train_model,\n",
        "                \"parameters\": parameters}\n",
        "\n",
        "  comparisons.append(comparison)"
      ],
      "metadata": {
        "id": "sOhn6FLJmuGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consigne** : Appeler la fonction précédente pour lancer les comparaisons définies à la cellule précédente."
      ],
      "metadata": {
        "id": "YGmj4ay1S4Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "fJeuWHAKS3yK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous venons de générer un objet *results* qui contient les types et les historiques des différentes expériences réalisées. Nous souhaitons les visualiser de manière simple.\n",
        "\n",
        "## Visualisation\n",
        "\n",
        "On se propose de construire une fonction qui exploite spécifiquement cette architecture d'objet pour le faire. Nous générerons deux figures:\n",
        "1. La valeur de la fonction de perte en fonction du temps d'entraînement\n",
        "2. La valeur de l'accuracy en fonction du temps d'entraînement\n",
        "\n",
        "Dans ces deux graphiques, nous présenterons en trait pleins la valeur de l'entraînement et en trait pointillés la valeur de la validation. Nous présenterons chaque type d'expérience sur chaque graphique accompagné de l'intervalle de confiance pour l'entraînement comme pour la validation."
      ],
      "metadata": {
        "id": "v2iTkq70MAvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_comparison(results,  title, confidence=3, figsize=(15, 6), alpha=0.1):\n",
        "\n",
        "    def agregate_result(key, metric_name):\n",
        "        training = np.zeros((comparisons_number, n_epochs))\n",
        "        validation = np.zeros((comparisons_number, n_epochs))\n",
        "        index = 0\n",
        "        for result in results:\n",
        "            if result[\"type\"] == key:\n",
        "                historic = result[\"history\"]\n",
        "                training[index] = historic[metric_name]\n",
        "                validation[index] = historic[\"val_%s\" % metric_name]\n",
        "                index += 1\n",
        "        return training, validation\n",
        "\n",
        "\n",
        "    def get_vector_mean_std(vector):\n",
        "        mean = vector.mean(axis=0)\n",
        "        std = vector.std(axis=0)\n",
        "        return mean, std\n",
        "\n",
        "\n",
        "\n",
        "    n_epochs = results[0][\"history\"].shape[0]\n",
        "    epochs = range(1, n_epochs+1)\n",
        "    comparisons_number = sum([result[\"type\"] == results[0][\"type\"] for result in results])\n",
        "    figure, (axis_1, axis_2) = plt.subplots(1, 2, figsize=figsize)\n",
        "    keys = list(set([result[\"type\"] for result in results]))\n",
        "\n",
        "\n",
        "    for metric_name, axis in zip([\"loss\", \"accuracy\"], [axis_1, axis_2]):\n",
        "\n",
        "        for index, key in enumerate(keys):\n",
        "            color = sns.color_palette()[index]\n",
        "            training, validation = agregate_result(key, metric_name)\n",
        "\n",
        "            training_mean, training_std = get_vector_mean_std(training)\n",
        "            axis.plot(epochs, training_mean, lw=2, label=key, color=color)\n",
        "            axis.fill_between(epochs, training_mean-confidence*training_std, training_mean+confidence*training_std, color=color, alpha=alpha)\n",
        "\n",
        "            validation_mean, validation_std = get_vector_mean_std(validation)\n",
        "            axis.plot(epochs, validation_mean, ls=\"--\", color=color)\n",
        "            axis.fill_between(epochs, validation_mean-confidence*validation_std, validation_mean+confidence*validation_std, color=color, alpha=alpha)\n",
        "\n",
        "        axis.set_ylabel(metric_name.capitalize())\n",
        "        axis.set_xlabel(\"Epochs\")\n",
        "        axis.set_title(\"%s through training\" % metric_name.capitalize())\n",
        "        axis.legend()\n",
        "\n",
        "\n",
        "    plt.suptitle(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "EUKMu1G5n-yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consigne** : utiliser la fonction précédente pour visualiser les courbes d'apprentissages."
      ],
      "metadata": {
        "id": "h-zs1gmiSsrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "E7oGaYXzS0JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consigne** : Commenter le précédent graphique."
      ],
      "metadata": {
        "id": "W9vsiLzwTaiy"
      }
    }
  ]
}